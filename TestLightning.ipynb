{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/configuration_validator.py:122: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1,2]\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | layer_1 | Linear | 100 K \n",
      "1 | layer_2 | Linear | 1.3 K \n",
      "-----------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "Epoch 0:   5%|▎     | 2826/60000 [00:14<04:51, 195.94it/s, loss=0.563, v_num=11]^C\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py:686: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "Epoch 0:   5%|▎     | 2826/60000 [00:14<04:53, 195.06it/s, loss=0.563, v_num=11]\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1,2 && python3 experiments/test_lightning.py --gpus 2 --strategy ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure(640x480)\n",
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py:1581: UserWarning: GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\n",
      "  \"GPU available but not used. Set the gpus flag in your trainer `Trainer(gpus=1)` or script `--gpus=1`.\"\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/configuration_validator.py:122: UserWarning: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "  rank_zero_warn(\"You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\")\n",
      "\n",
      "  | Name   | Type       | Params\n",
      "--------------------------------------\n",
      "0 | blocks | ModuleList | 596   \n",
      "--------------------------------------\n",
      "596       Trainable params\n",
      "0         Non-trainable params\n",
      "596       Total params\n",
      "0.002     Total estimated model params size (MB)\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:117: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  f\"The dataloader, {name}, does not have many workers which may be a bottleneck.\"\n",
      "/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/data_loading.py:413: UserWarning: The number of training samples (17) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
      "Epoch 0:   0%|                                           | 0/17 [00:00<?, ?it/s]/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Traceback (most recent call last):\n",
      "  File \"experiments/test_moons.py\", line 538, in <module>\n",
      "    main_lightning(args)\n",
      "  File \"experiments/test_moons.py\", line 505, in main_lightning\n",
      "    trainer.fit(lit_model, train_loader)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 739, in fit\n",
      "    self._fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 683, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 773, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1195, in _run\n",
      "    self._dispatch()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1275, in _dispatch\n",
      "    self.training_type_plugin.start_training(self)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 202, in start_training\n",
      "    self._results = trainer.run_stage()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1285, in run_stage\n",
      "    return self._run_train()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\", line 1315, in _run_train\n",
      "    self.fit_loop.run()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/fit_loop.py\", line 234, in advance\n",
      "    self.epoch_loop.run(data_fetcher)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py\", line 193, in advance\n",
      "    batch_output = self.batch_loop.run(batch, batch_idx)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py\", line 88, in advance\n",
      "    outputs = self.optimizer_loop.run(split_batch, optimizers, batch_idx)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/base.py\", line 145, in run\n",
      "    self.advance(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 219, in advance\n",
      "    self.optimizer_idx,\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 266, in _run_optimization\n",
      "    self._optimizer_step(optimizer, opt_idx, batch_idx, closure)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 386, in _optimizer_step\n",
      "    using_lbfgs=is_lbfgs,\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/core/lightning.py\", line 1652, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/core/optimizer.py\", line 164, in step\n",
      "    trainer.accelerator.optimizer_step(self._optimizer, self._optimizer_idx, closure, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 336, in optimizer_step\n",
      "    self.precision_plugin.optimizer_step(model, optimizer, opt_idx, closure, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 163, in optimizer_step\n",
      "    optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/autograd/grad_mode.py\", line 26, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/optim/adam.py\", line 66, in step\n",
      "    loss = closure()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py\", line 148, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 160, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 142, in closure\n",
      "    step_output = self._step_fn()\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/loops/optimization/optimizer_loop.py\", line 435, in _training_step\n",
      "    training_step_output = self.trainer.accelerator.training_step(step_kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\", line 216, in training_step\n",
      "    return self.training_type_plugin.training_step(*step_kwargs.values())\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\", line 213, in training_step\n",
      "    return self.model.training_step(*args, **kwargs)\n",
      "  File \"experiments/test_moons.py\", line 336, in training_step\n",
      "    test_data = self.reverse(self.z_sample).cpu().data\n",
      "  File \"experiments/test_moons.py\", line 317, in reverse\n",
      "    input = block.reverse(z_list[-1], z_list[-1])\n",
      "  File \"experiments/test_moons.py\", line 262, in reverse\n",
      "    mean, log_sd = self.prior(zero).chunk(2, 1)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"experiments/test_moons.py\", line 171, in forward\n",
      "    return self.fc(input)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 93, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/torch/nn/functional.py\", line 1690, in linear\n",
      "    ret = torch.addmm(bias, input, weight.t())\n",
      "RuntimeError: Tensor for 'out' is on CPU, Tensor for argument #1 'self' is on CPU, but expected them to be on GPU (while checking arguments for addmm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <object repr() failed>\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/tqdm/std.py\", line 1135, in __del__\r\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/tqdm/std.py\", line 1282, in close\r\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/tqdm/std.py\", line 1467, in display\r\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/tqdm/std.py\", line 1138, in __repr__\r\n",
      "  File \"/home/user/miniconda/envs/py36/lib/python3.6/site-packages/tqdm/std.py\", line 1425, in format_dict\r\n",
      "TypeError: 'NoneType' object is not iterable\r\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=1,2 && python3 experiments/test_moons.py --gpus 2 --strategy ddp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py  lightning_logs  moons_0.png  test_lightning.py  test_moons.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls experiments"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}